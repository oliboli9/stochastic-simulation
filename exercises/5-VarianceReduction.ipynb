{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2993a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize_scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96955076",
   "metadata": {},
   "source": [
    "## Task 1: Crude Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2c81267",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_value = np.exp(1) - 1 # exact value of the integral from 0 to 1 of e^x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5306599",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "samples = np.random.uniform(0, 1, n)\n",
    "f_values = np.exp(samples)\n",
    "estimate = np.mean(f_values)\n",
    "std_dev = np.std(f_values, ddof=1)\n",
    "conf_interval = (estimate - 1.96 * std_dev / np.sqrt(n), estimate + 1.96 * std_dev / np.sqrt(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "968387e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate of int = E[e^X]: 1.7258371186819246\n",
      "95% confidence interval: (1.6353817241966986, 1.8162925131671506)\n",
      "Confidence interval width: 0.18091078897045199\n",
      "Error from exact value: 0.007555290222879485\n"
     ]
    }
   ],
   "source": [
    "print(f\"Estimate of int = E[e^X]: {estimate}\")\n",
    "print(f\"95% confidence interval: {conf_interval}\")\n",
    "print(f\"Confidence interval width: {conf_interval[1] - conf_interval[0]}\")\n",
    "print(f\"Error from exact value: {estimate - exact_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb8a73c",
   "metadata": {},
   "source": [
    "## Task 2: Antithetic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbe2e1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = n // 2 # 100 function evaluations, so we generate 50 random values\n",
    "u = np.random.uniform(0, 1, m)\n",
    "f_values = (np.exp(u) + np.exp(1 - u)) / 2\n",
    "estimate = np.mean(f_values)\n",
    "std_dev = np.std(f_values, ddof=1)\n",
    "conf_interval = (estimate - 1.96 * std_dev / np.sqrt(m), estimate + 1.96 * std_dev / np.sqrt(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66b31959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate of int = E[e^X]: 1.727874528575985\n",
      "95% confidence interval: (1.7069281180731772, 1.7488209390787925)\n",
      "Confidence interval width: 0.04189282100561531\n",
      "Error from exact value: 0.0095927001169398\n"
     ]
    }
   ],
   "source": [
    "print(f\"Estimate of int = E[e^X]: {estimate}\")\n",
    "print(f\"95% confidence interval: {conf_interval}\")\n",
    "print(f\"Confidence interval width: {conf_interval[1] - conf_interval[0]}\")\n",
    "print(f\"Error from exact value: {estimate - exact_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507bce37",
   "metadata": {},
   "source": [
    "## Task 3: Control variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19b1f453",
   "metadata": {},
   "outputs": [],
   "source": [
    "U = np.random.uniform(0, 1, n)\n",
    "X = np.exp(U)\n",
    "Y = U\n",
    "mu_Y = 0.5 # known mean of Y\n",
    "\n",
    "# estimate optimal c\n",
    "cov_XY = np.cov(X, Y, ddof=1)[0, 1]\n",
    "var_Y = np.var(Y, ddof=1)\n",
    "c = -cov_XY / var_Y \n",
    "\n",
    "# construct Z_i and estimate its mean\n",
    "Z = X + c * (Y - mu_Y)\n",
    "estimate = np.mean(Z)\n",
    "std_dev = np.std(Z, ddof=1)\n",
    "conf_interval = (estimate - 1.96 * std_dev / np.sqrt(n), estimate + 1.96 * std_dev / np.sqrt(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df9bb961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate of int = E[e^X]: 1.7199960030530008\n",
      "95% confidence interval: (1.7072200938765887, 1.732771912229413)\n",
      "Confidence interval width: 0.025551818352824274\n",
      "Error from exact value: 0.0017141745939557307\n"
     ]
    }
   ],
   "source": [
    "print(f\"Estimate of int = E[e^X]: {estimate}\")\n",
    "print(f\"95% confidence interval: {conf_interval}\")\n",
    "print(f\"Confidence interval width: {conf_interval[1] - conf_interval[0]}\")\n",
    "print(f\"Error from exact value: {estimate - exact_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac58008",
   "metadata": {},
   "source": [
    "## Task 4: Stratified sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de03dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of strata (and samples)\n",
    "k = 100\n",
    "U = np.random.uniform(0, 1, k)\n",
    "\n",
    "x_strata = (np.arange(k) + U) / k  # (j - 1 + U_j) / k\n",
    "f_vals = np.exp(x_strata)\n",
    "\n",
    "estimate = np.mean(f_vals)\n",
    "std_dev = np.std(f_vals, ddof=1)\n",
    "conf_interval = (estimate - 1.96 * std_dev / np.sqrt(k), estimate + 1.96 * std_dev / np.sqrt(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca2ac522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate of int = E[e^X]: 1.7169735989631407\n",
      "95% confidence interval: (1.6203383034404866, 1.8136088944857949)\n",
      "Confidence interval width: 0.1932705910453083\n",
      "Error from exact value: -0.0013082294959043672\n"
     ]
    }
   ],
   "source": [
    "print(f\"Estimate of int = E[e^X]: {estimate}\")\n",
    "print(f\"95% confidence interval: {conf_interval}\")\n",
    "print(f\"Confidence interval width: {conf_interval[1] - conf_interval[0]}\")\n",
    "print(f\"Error from exact value: {estimate - exact_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9c2d6b",
   "metadata": {},
   "source": [
    "## Task 5: Control variates for previous exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6f0c08",
   "metadata": {},
   "source": [
    "See end of notebook 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c55797",
   "metadata": {},
   "source": [
    "## Task 6: CRN in Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bf3b1b",
   "metadata": {},
   "source": [
    "See end of notebook 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587e59ae",
   "metadata": {},
   "source": [
    "## Task 7: Importance sampling vs crude Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "788900d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from exercise 3:\n",
    "def simulate_normal_box_muller(n):\n",
    "    U1 = np.random.uniform(size=n//2)\n",
    "    U2 = np.random.uniform(size=n//2)\n",
    "\n",
    "    R = np.sqrt(-2 * np.log(U1))\n",
    "    theta = 2 * np.pi * U2\n",
    "\n",
    "    Z1 = R * np.cos(theta)\n",
    "    Z2 = R * np.sin(theta)\n",
    "\n",
    "    Z = np.concatenate([Z1, Z2])\n",
    "    return Z \n",
    "\n",
    "# pdf normal\n",
    "def normal_pdf(x, mu=0, sigma=1):\n",
    "    coeff = 1.0 / (np.sqrt(2 * np.pi) * sigma)\n",
    "    exponent = -((x - mu) ** 2) / (2 * sigma ** 2)\n",
    "    return coeff * np.exp(exponent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59e5f154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "a_values = [2, 4]  # thresholds\n",
    "sample_sizes = [100, 1000, 10000]\n",
    "sigma2 = 1  # for importance sampling\n",
    "\n",
    "results = []\n",
    "\n",
    "for a in a_values:\n",
    "    for n in sample_sizes:\n",
    "\n",
    "        # crude Monte Carlo:\n",
    "        Z = simulate_normal_box_muller(n)\n",
    "        crude_probs = Z > a\n",
    "        crude_estimate = np.mean(crude_probs)\n",
    "        crude_std_error = np.std(crude_probs, ddof=1) / np.sqrt(n)\n",
    "\n",
    "        # importance sampling:\n",
    "        mu = a \n",
    "        sigma = np.sqrt(sigma2)\n",
    "\n",
    "        # simulate standard normals using Box-Muller\n",
    "        Z = simulate_normal_box_muller(n)\n",
    "        # shift and scale to sample from g = N(mu, sigma^2)\n",
    "        Y = mu + sigma * Z\n",
    "\n",
    "        # compute weights f(Y) / g(Y)\n",
    "        f_Y = normal_pdf(Y, mu=0, sigma=1) # standard normal\n",
    "        g_Y = normal_pdf(Y, mu=mu, sigma=sigma) # importance distribution\n",
    "        weights = f_Y / g_Y\n",
    "\n",
    "        indicators = (Y > a)\n",
    "        imp_estimate = np.mean(indicators * weights)\n",
    "        imp_std_error = np.std(indicators * weights, ddof=1) / np.sqrt(n)      \n",
    "\n",
    "        results.append({\n",
    "            'a': a,\n",
    "            'n': n,\n",
    "            'crude_estimate': crude_estimate,\n",
    "            'crude_std_error': crude_std_error,\n",
    "            'importance_estimate': imp_estimate,\n",
    "            'importance_std_error': imp_std_error\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef33345b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 2, n = 100\n",
      "  Crude MC estimate: 0.010000 ± 0.019600\n",
      "  IS estimate      : 0.022793 ± 0.007447\n",
      "\n",
      "a = 2, n = 1000\n",
      "  Crude MC estimate: 0.017000 ± 0.008016\n",
      "  IS estimate      : 0.023493 ± 0.002201\n",
      "\n",
      "a = 2, n = 10000\n",
      "  Crude MC estimate: 0.019500 ± 0.002710\n",
      "  IS estimate      : 0.021763 ± 0.000666\n",
      "\n",
      "a = 4, n = 100\n",
      "  Crude MC estimate: 0.000000 ± 0.000000\n",
      "  IS estimate      : 0.000038 ± 0.000015\n",
      "\n",
      "a = 4, n = 1000\n",
      "  Crude MC estimate: 0.000000 ± 0.000000\n",
      "  IS estimate      : 0.000029 ± 0.000004\n",
      "\n",
      "a = 4, n = 10000\n",
      "  Crude MC estimate: 0.000000 ± 0.000000\n",
      "  IS estimate      : 0.000031 ± 0.000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for r in results:\n",
    "    print(f\"a = {r['a']}, n = {r['n']}\")\n",
    "    print(f\"  Crude MC estimate: {r['crude_estimate']:.6f} ± {1.96*r['crude_std_error']:.6f}\")\n",
    "    print(f\"  IS estimate      : {r['importance_estimate']:.6f} ± {1.96*r['importance_std_error']:.6f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be3f6eb",
   "metadata": {},
   "source": [
    "- Crude MC works okay for moderate tail probabilities but fails for very rare events. (In the case where a = 4). Confidence interval captures true value for Crude MC for a = 2. \n",
    "\n",
    "- Importance sampling significantly reduces variance for rare-event probabilities and provides meaningful estimates even with modest samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd7d7db",
   "metadata": {},
   "source": [
    "## Task 8: Importance sampling exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4cc0a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Exercise 3\n",
    "def simulate_exponential(n, lam):\n",
    "    U = np.random.uniform(size=n)\n",
    "    X = -np.log(U) / lam\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308c3420",
   "metadata": {},
   "source": [
    "The estimator is\n",
    "$$\n",
    "\\theta = \\frac{1}{n} \\sum_{i=1}^n h(Y_i) \\frac{f(Y_i)}{g(Y_i)}, \\quad Y_i \\sim g\n",
    "$$\n",
    "\n",
    "- $h(x) = \\mathbf{1}_{x \\leq 1}$ because the integral is over [0,1].\n",
    "- $f(x) = e^x$\n",
    "-  $g(x) = \\lambda e^{-\\lambda x}$\n",
    "\n",
    "We sample $Y_i$ from the exponential distribution $g$ and weight samples inside the integration domain \\[0,1]:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{1}_{Y_i \\leq 1} \\cdot e^{Y_i} \\frac{1}{\\lambda e^{-\\lambda Y_i}} = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{1}_{Y_i \\leq 1} \\frac{e^{Y_i(1+\\lambda)}}{\\lambda}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2977ac",
   "metadata": {},
   "source": [
    "To find the optimal $\\lambda$ for importance sampling with $g(x) = \\lambda e^{-\\lambda x}$ when estimating $\\int_0^1 e^x dx$, we analyze the variance of $W = \\frac{h(x)f(x)}{g(x)}$\n",
    "\n",
    "$$\n",
    "W = \\mathbf{1}_{x \\leq 1} \\frac{e^{x(1+\\lambda)}}{\\lambda}\n",
    "$$\n",
    "\n",
    "The variance is\n",
    "\n",
    "$$\n",
    "\\text{Var}(W) = E_g[W^2] - (E_g[W])^2 \n",
    "$$\n",
    "\n",
    "We have\n",
    "\\begin{align*}\n",
    "    E_g[W^2] &= \\int_0^1 \\left( \\frac{e^{x(1+\\lambda)}}{\\lambda} \\right)^2 \\cdot \\lambda e^{-\\lambda x} dx = \\frac{1}{\\lambda^2} \\int_0^1 e^{2x(1+\\lambda)} \\cdot \\lambda e^{-\\lambda x} dx \\\\\n",
    "    & = \\frac{\\lambda}{\\lambda^2} \\int_0^1 e^{(2+\\lambda) x} dx = \\frac{1}{\\lambda} \\int_0^1 e^{(2+\\lambda) x} dx  = \\frac{e^{2+\\lambda} - 1}{2 + \\lambda}\n",
    "\\end{align*}\n",
    "\n",
    "Therefore, \n",
    "\n",
    "$$\n",
    "\\text{Var}(W) = E_g[W^2] - (E_g[W])^2 = \\frac{1}{\\lambda} \\cdot \\frac{e^{2+\\lambda} - 1}{2 + \\lambda} - (e - 1)^2\n",
    "$$\n",
    "\n",
    "\n",
    "We can numerically find the $\\lambda$ that minimizes this variance. However, as expected from theory, using the exponential distribution $g$ here does not significantly reduce variance compared to crude Monte Carlo, because many samples fall outside the interval $[0,1]$ and contribute zero to the estimator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89833fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal lambda: 1.3548\n"
     ]
    }
   ],
   "source": [
    "def variance_W(lam):\n",
    "    if lam <= 0:\n",
    "        return np.inf\n",
    "    EgW2 = (1 / lam) * (np.exp(2 + lam) - 1) / (2 + lam)\n",
    "    EgW = np.exp(1) - 1\n",
    "    var = EgW2 - EgW**2\n",
    "    return var\n",
    "\n",
    "# minimize variance over lambda > 0\n",
    "res = minimize_scalar(variance_W, bounds=(0.01, 10), method='bounded')\n",
    "optimal_lambda = res.x\n",
    "\n",
    "print(f\"Optimal lambda: {optimal_lambda:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1371e6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importance sampling estimates for various lambda:\n",
      "lambda=0.1000: Estimate = 1.776642 ± 0.057055\n",
      "lambda=0.5000: Estimate = 1.728338 ± 0.024458\n",
      "lambda=1.0000: Estimate = 1.729109 ± 0.018409\n",
      "lambda=1.3548: Estimate = 1.750560 ± 0.018141\n",
      "lambda=2.0000: Estimate = 1.727724 ± 0.019663\n",
      "lambda=5.0000: Estimate = 1.762760 ± 0.053452\n"
     ]
    }
   ],
   "source": [
    "def importance_sampling_exp(lam, n=10000):\n",
    "    X = simulate_exponential(n, lam)\n",
    "    indicators = (X <= 1)\n",
    "    weights = indicators * (np.exp(X * (1 + lam)) / lam)\n",
    "    estimate = np.mean(weights)\n",
    "    std_error = np.std(weights, ddof=1) / np.sqrt(n)\n",
    "    return estimate, std_error\n",
    "\n",
    "# run for some lambdas\n",
    "lam_values = [0.1, 0.5, 1.0, 1.3548, 2.0, 5.0]\n",
    "n = 10000\n",
    "\n",
    "print(\"Importance sampling estimates for various lambda:\")\n",
    "for lam in lam_values:\n",
    "    est_is, se_is = importance_sampling_exp(lam, n)\n",
    "    print(f\"lambda={lam:.4f}: Estimate = {est_is:.6f} ± {se_is:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c284989",
   "metadata": {},
   "source": [
    "Optimal value for lambda seems correct from simulation/ test of different lambda values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1c6f0f",
   "metadata": {},
   "source": [
    "## Task 9: Importance sampling Pareto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0d7026",
   "metadata": {},
   "source": [
    "Given a Pareto-distributed random variable:\n",
    "\n",
    "$$\n",
    "X \\sim \\text{Pareto}(k, \\beta),\n",
    "$$\n",
    "\n",
    "with PDF:\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{k}{\\beta} \\left(\\frac{x}{\\beta}\\right)^{-k-1}, \\quad x \\ge \\beta,\n",
    "$$\n",
    "\n",
    "and CDF:\n",
    "\n",
    "$$\n",
    "F(x) = 1 - \\left(\\frac{\\beta}{x}\\right)^k.\n",
    "$$\n",
    "\n",
    "We want to estimate the mean $\\mathbb{E}[X]$ using importance sampling, where the sampling distribution is the first moment distribution of $X$.\n",
    "\n",
    "For nonnegative random variables, the first moment distribution is defined as (from lecture notes):\n",
    "\n",
    "$$\n",
    "G_1(x) = \\frac{1}{\\mathbb{E}[X]} \\int_{\\beta}^x t f(t) \\, dt,\n",
    "$$\n",
    "\n",
    "where $\\mathbb{E}[X]$ is the first moment of $X$, and the integral gives the contribution to the first moment from values $\\leq x$.\n",
    "\n",
    "We have:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X] = \\int_{\\beta}^{\\infty} x f(x) \\, dx = \\frac{k \\beta}{k - 1}, \\quad \\text{for } k > 1.\n",
    "$$\n",
    "\n",
    "Now compute $G_1(x)$:\n",
    "\n",
    "$$\n",
    "G_1(x) = \\frac{1}{\\mathbb{E}[X]} \\int_{\\beta}^{x} t f(t) \\, dt = \\frac{1}{\\frac{k \\beta}{k - 1}} \\int_{\\beta}^{x} t \\cdot \\frac{k}{\\beta} \\left(\\frac{t}{\\beta}\\right)^{-k-1} dt.\n",
    "$$\n",
    "\n",
    "Rewrite the integral:\n",
    "\n",
    "$$\n",
    "= \\frac{k - 1}{k \\beta} \\cdot k \\beta^k \\int_{\\beta}^{x} t^{-k} dt = (k - 1) \\beta^{k - 1} \\int_{\\beta}^{x} t^{-k} dt.\n",
    "$$\n",
    "\n",
    "Integrating:\n",
    "\n",
    "$$\n",
    "\\int_{\\beta}^{x} t^{-k} dt = \\left[ \\frac{t^{-k + 1}}{-k + 1} \\right]_{\\beta}^{x} = \\frac{1}{k - 1} \\left(\\beta^{-k + 1} - x^{-k + 1}\\right),\n",
    "$$\n",
    "\n",
    "so:\n",
    "\n",
    "$$\n",
    "G_1(x) = (k - 1) \\beta^{k - 1} \\cdot \\frac{1}{k - 1} \\left(\\beta^{-k + 1} - x^{-k + 1}\\right) = 1 - \\left(\\frac{\\beta}{x}\\right)^{k - 1}.\n",
    "$$\n",
    "\n",
    "Thus, the CDF of the first moment distribution is:\n",
    "\n",
    "$$\n",
    "G_1(x) = 1 - \\left(\\frac{\\beta}{x}\\right)^{k - 1}, \\quad x \\ge \\beta,\n",
    "$$\n",
    "\n",
    "which is again a Pareto distribution with shape parameter $k - 1$. So:\n",
    "\n",
    "$$\n",
    "X_{\\text{IS}} \\sim \\text{Pareto}(k - 1, \\beta).\n",
    "$$\n",
    "\n",
    "We now estimate the mean using importance sampling:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X] = \\int_{\\beta}^{\\infty} x f(x) \\, dx = \\int_{\\beta}^{\\infty} x \\cdot \\frac{f(x)}{g(x)} \\cdot g(x) \\, dx = \\mathbb{E}_g\\left[x \\cdot \\frac{f(x)}{g(x)}\\right],\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "g(x) = \\frac{d}{dx} G_1(x) = \\frac{(k - 1) \\beta^{k - 1}}{x^{k}}.\n",
    "$$\n",
    "\n",
    "Now compute the weight:\n",
    "\n",
    "$$\n",
    "\\frac{f(x)}{g(x)} = \\frac{\\frac{k}{\\beta} \\left(\\frac{x}{\\beta}\\right)^{-k-1}}{\\frac{(k - 1) \\beta^{k - 1}}{x^{k}}} = \\frac{\\frac{k}{\\beta} \\cdot \\beta^{k+1} x^{-k-1}}{\\frac{(k-1) \\beta^{k-1}}{x^{k}}} = \\frac{k}{k-1} \\cdot \\frac{\\beta}{x}.\n",
    "$$\n",
    "\n",
    "Therefore, the IS estimator is:\n",
    "\n",
    "$$\n",
    "\\hat{\\mu}_{\\text{IS}} = \\frac{1}{n} \\sum_{i=1}^n X_i \\cdot \\frac{f(X_i)}{g(X_i)} = \\frac{1}{n} \\sum_{i=1}^n X_i \\cdot \\frac{k}{k - 1} \\cdot \\frac{\\beta}{X_i} = \\frac{k}{k - 1} \\cdot \\beta.\n",
    "$$\n",
    "\n",
    "The estimator simplifies to a constant, meaning that this specific importance sampling strategy gives us the exact value of the mean without any sampling error. This makes sense, since the proposal distribution is chosen to be proportional to the integrand, it's effectively the optimal choice for this problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c83001",
   "metadata": {},
   "source": [
    "A better choice of $g(x)$ in Question 8 would be the first moment distribution on $[0, 1]$, so we give more weight to larger values of $x$, where $e^x$ is large, and align the sampling distribution with the shape of the integrand.\n",
    "\n",
    "Let $X \\sim \\text{Uniform}(0, 1)$, with density $f(x) = 1$ on $[0,1] $. The first moment distribution has CDF:\n",
    "\n",
    "$$\n",
    "G_1(x) = \\frac{1}{\\mathbb{E}[X]} \\int_0^x t f(t) \\, dt = \\frac{1}{\\mathbb{E}[X]} \\int_0^x t \\, dt\n",
    "$$\n",
    "\n",
    "We compute:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X] = \\int_0^1 x \\cdot 1 \\, dx = \\frac{1}{2}\n",
    "$$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "G_1(x) = \\frac{1}{1/2} \\int_0^x t \\, dt = 2 \\cdot \\left[ \\frac{t^2}{2} \\right]_0^x = x^2\n",
    "$$\n",
    "\n",
    "Thus, the CDF of the first moment distribution is:\n",
    "\n",
    "$$\n",
    "G_1(x) = x^2, \\quad x \\in [0, 1]\n",
    "$$\n",
    "\n",
    "Taking the derivative gives the density:\n",
    "\n",
    "$$\n",
    "g(x) = \\frac{d}{dx} G_1(x) = 2x\n",
    "$$\n",
    "\n",
    "\n",
    "So $g(x) = 2x$ is a better probability density function on $[0, 1]$, and we could sample from it to concentrate more samples where $e^x$ is large, leading to a lower-variance and more efficient importance sampling estimator for the integral.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
